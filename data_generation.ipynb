{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "data_generation.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/love-bees/twitter/blob/master/data_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuRP634lwAe5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tweepy, csv\n",
        "\n",
        "auth = tweepy.OAuthHandler('bzzz', 'bzzz')\n",
        "\n",
        "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMiXji_8wAfW",
        "colab_type": "code",
        "colab": {},
        "outputId": "2d7fa7f4-7858-480f-8021-3e4314c8a967"
      },
      "source": [
        "new_tweets = 0\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        tweet_ids = [int(tweet_id) for tweet_id in open('gathered_tweet_ids.txt', 'r').read().split(\"\\n\") if tweet_id.strip() != \"\"]\n",
        "\n",
        "        csv_file = open(\"data.csv\", \"a\")\n",
        "        csv_writer = csv.writer(csv_file)\n",
        "\n",
        "        for tweet in tweepy.Cursor(api.search, q = \"covid\", since_id = max(tweet_ids),\n",
        "                                   #since = \"2020-04-05\", until = \"2020-04-06\", \n",
        "                                   tweet_mode = \"extended\", count = 100).items():\n",
        "\n",
        "            if tweet.geo:\n",
        "                if tweet.id not in tweet_ids:\n",
        "\n",
        "                    csv_writer.writerow([tweet.id_str, str(tweet.created_at),\n",
        "                                         \", \".join([str(xy) for xy in tweet.coordinates[\"coordinates\"][::-1]]), tweet.lang, \n",
        "                                         \" \".join([hashtag[\"text\"] for hashtag in tweet.entities[\"hashtags\"]]).encode(\"utf-8\"), \n",
        "                                         tweet.full_text.encode('utf-8')])\n",
        "\n",
        "                    with open('gathered_tweet_ids.txt', 'a') as file:\n",
        "                        file.write(\"\\n\" + str(tweet.id))\n",
        "                    tweet_ids.append(tweet.id)\n",
        "\n",
        "                    print(\"Tweets collected: \" + str(len(tweet_ids)))\n",
        "                    csv_file.flush()\n",
        "\n",
        "                    new_tweets += 1\n",
        "                    \n",
        "                    if new_tweets == 50:\n",
        "                        new_tweets = 0\n",
        "                        csv_file.close()\n",
        "                        break\n",
        "    except:\n",
        "        continue"
      ],
      "execution_count": 0
